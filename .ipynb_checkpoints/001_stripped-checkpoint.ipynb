{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO-v3 for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cat darknet/cfg/yolov3.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "INPUT_SIZE = 416\n",
    "\n",
    "ANCHORS = np.array([(10,13),(16,30),(33,23),(30,61),(62,45),(59,119),(116,90),(156,198),(373,326)],\n",
    "                   np.float32)\n",
    "\n",
    "ANCHORS = ANCHORS/INPUT_SIZE\n",
    "\n",
    "MASK = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n",
    "MAX_BOXES = 100\n",
    "\n",
    "IOU_THRES = 0.5\n",
    "SCORE_THRES = 0.5\n",
    "DECAY = 0.0005\n",
    "MOMENTUM = 0.9\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 80\n",
    "\n",
    "\n",
    "WEIGHT_FILE = \"../DeepLearning/Computer-Vision/CVND_Exercises/2_2_YOLO/cfg/yolov3.weights\"\n",
    "OUTPUT_DIR = Path(\"outputs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Darknet Utils:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def darknet_conv(x, filters, kernel_size, strides=1, bnorm=True):\n",
    "    \"\"\"\n",
    "    Creates a Standard Darknet Layer: \n",
    "    inp => Conv => BatchNorm[Optional] => LeakyReLU[Optional]\n",
    "    \"\"\"\n",
    "    if strides == 1:    padding = \"same\"\n",
    "    else:\n",
    "        x = keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n",
    "        padding = 'valid'\n",
    "        \n",
    "    x = keras.layers.Conv2D(\n",
    "        filters=filters, kernel_size=kernel_size,\n",
    "        strides=strides, padding=padding,\n",
    "        use_bias=not bnorm, kernel_regularizer=l2(DECAY))(x)\n",
    "    \n",
    "    if bnorm:\n",
    "        x = keras.layers.BatchNormalization(momentum=MOMENTUM)(x)\n",
    "        x = keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def darknet_residual(x, filters):\n",
    "    \"\"\"\n",
    "    Creates a Standard DarkNet Residual Connection\n",
    "    inp => darknet_conv => darknet_conv => Add[inp, darknet_conv]\n",
    "    \"\"\"\n",
    "    prev = x\n",
    "    x = darknet_conv(x, filters//2, kernel_size=1)\n",
    "    x = darknet_conv(x, filters,    kernel_size=3)\n",
    "    x = keras.layers.Add()([prev, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def darknet_block(x, filters, nums):\n",
    "    \"\"\"\n",
    "    Creates a Standard Darknet Block\n",
    "    inp => darknet_conv => nums x darknet_residual\n",
    "    \"\"\"\n",
    "    x = darknet_conv(x, filters, kernel_size=3, strides=2)\n",
    "    for _ in range(nums):\n",
    "        x = darknet_residual(x, filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Darknet_53`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def Darknet_53(size=INPUT_SIZE, channels=CHANNELS, **kwargs):\n",
    "    \"\"\"\n",
    "    Creates the Darknet_53 Module\n",
    "    \"\"\"\n",
    "    x = inputs = keras.Input([size, size, channels])\n",
    "    x = darknet_conv(inputs, 32, kernel_size=3)\n",
    "    x = darknet_block(x, 64, nums=1)\n",
    "    x = darknet_block(x, 128, nums=2)\n",
    "    x = route_1 = darknet_block(x, 256, nums=8)\n",
    "    x = route_2 = darknet_block(x, 512, nums=8)\n",
    "    x = route_3 = darknet_block(x, 1024, nums=4)\n",
    "    return keras.Model(inputs, outputs=(route_1, route_2, route_3), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `YOLO Utils`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def yolo_layer(filters, name=None):\n",
    "    def output(x_in):\n",
    "        \"\"\"\n",
    "        Wrapper for 5 \n",
    "        Darknet_conv layers in succession with :\n",
    "           filters = [filters, filters*2, filters, filters*2, filters] \n",
    "                 & \n",
    "           kernel_size  = [1, 3, 1, 3, 1]\n",
    "        \"\"\"\n",
    "        if isinstance(x_in, tuple):\n",
    "            # if not the first output skip connection\n",
    "            inputs = keras.Input(x_in[0].shape[1:]), keras.Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "            # concat with skip connection\n",
    "            x = darknet_conv(x, filters, 1)\n",
    "            x = keras.layers.UpSampling2D(2, interpolation=\"bilinear\")(x)\n",
    "            x = keras.layers.Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            # no skip connection for the first output\n",
    "            x = inputs = keras.Input(x_in.shape[1:])\n",
    "        x = darknet_conv(x, filters, 1)\n",
    "        x = darknet_conv(x, filters * 2, 3)\n",
    "        x = darknet_conv(x, filters, 1)\n",
    "        x = darknet_conv(x, filters * 2, 3)\n",
    "        x = darknet_conv(x, filters, 1)\n",
    "        return keras.Model(inputs, x, name=name)(x_in)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def yolo_output_layer(filters, num_anchors, num_classes, name=None):\n",
    "    def output(x_in):\n",
    "        \"\"\"\n",
    "        Processes & reshapes outputs into:\n",
    "        [batch_size, grid_size, grid_size, num_anchors, (num_classes+5)]\n",
    "        \"\"\"\n",
    "        x = inputs = keras.Input(x_in.shape[1:])\n",
    "        x = darknet_conv(x, filters * 2, 3)\n",
    "        x = darknet_conv(x, num_anchors*(num_classes+5), 1, bnorm=False)\n",
    "        # Reshape into required output shape\n",
    "        x = keras.layers.Lambda(\n",
    "            lambda x: tf.reshape(x, shape=(-1, tf.shape(x)[1], tf.shape(x)[2], num_anchors, num_classes+5))\n",
    "        )(x)\n",
    "        \n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `YOLO_V3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def YOLO(size=INPUT_SIZE, channels=CHANNELS, anchors=ANCHORS, mask=MASK, num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Creates a YOLO_V3 Model\n",
    "    \"\"\"\n",
    "    x = inputs = keras.Input([size, size, channels], name=\"INPUT-416x416x3\")\n",
    "    # Feature extractor : Darknet_53\n",
    "    route_1, route_2, x = Darknet_53(name=\"DARKNET-53\")(x)\n",
    "    \n",
    "    # darknet_conv => output_1\n",
    "    x = yolo_layer(filters=512, name=\"YOLO_LAYER_0\")(x)\n",
    "    output_0 = yolo_output_layer(512, len(mask[0]), num_classes, \"YOLO_OUTPUT_0\")(x)\n",
    "    \n",
    "    # skip connection => datknet_conv => output_2\n",
    "    x = yolo_layer(256, name=\"YOLO_LAYER_1\")((x, route_2))\n",
    "    output_1 = yolo_output_layer(256, len(mask[1]), num_classes, \"YOLO_OUTPUT_1\")(x)\n",
    "    \n",
    "    # skip connection => datknet_conv => output_3\n",
    "    x = yolo_layer(128, name=\"YOLO_LAYER_2\")((x, route_1))\n",
    "    output_2 = yolo_output_layer(128, len(mask[2]), num_classes, \"YOLO_OUTPUT_2\")(x)\n",
    "    \n",
    "    return keras.Model(inputs, outputs=(output_0, output_1, output_2), name=\"YOLO_V3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Prediction Utils`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def cvt_boxes(pred, t_xy, t_wh, anchors):\n",
    "    \"\"\"\n",
    "    Arguments: t_xy, t_wh, anchors\n",
    "    \"\"\"\n",
    "    # Calculate the grid_size\n",
    "    grid_size = tf.shape(pred)[1:3]\n",
    "    \n",
    "    # create grid offsets\n",
    "    grid = tf.meshgrid(tf.range(grid_size[1]), tf.range(grid_size[0]))\n",
    "    # out: (grid_size,grid_size),(grid_size,grid_size)\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "    # out: (grid_size, grid_size, 2) -> (grid_size, grid_size, 1, 2)\n",
    "    \n",
    "    # sigmoid and add offset & scale with achors\n",
    "    ## Normalize\n",
    "    box_xy = (tf.sigmoid(t_xy) + tf.cast(grid, tf.float32))/ tf.cast(grid_size, tf.float32)\n",
    "    wh = tf.exp(t_wh) * anchors\n",
    "     \n",
    "    # [x1, y1, x2, y2]: Normalized\n",
    "    box_x1y1 = box_xy - wh / 2\n",
    "    box_x2y2 = box_xy + wh / 2\n",
    "    \n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def decode_preds(preds, anchors, num_classes=NUM_CLASSES, inp_dim=INPUT_SIZE):\n",
    "    \"\"\"\n",
    "    Decode Final Layer Predicitons from YOLO Model\n",
    "    \"\"\"\n",
    "    # preds: [batch_size, grid, grid, num_anchors, x, y, w, h, obj, classes ...]\n",
    "    # Grab t_xy, t_wh, objectness, class_probs from the given predictions\n",
    "    t_xy, t_wh, objectness, class_probs = tf.split(preds, (2, 2, 1, num_classes), axis=-1)\n",
    "    \n",
    "    # Calcualte objectness and class probs\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    bbox = cvt_boxes(preds, t_xy, t_wh, anchors)\n",
    "    \n",
    "    # concat: shape[batch_size, grid_size, grid_size, num_anchors, (5+num_classes)]\n",
    "    outputs = tf.concat([bbox, objectness, class_probs], axis=-1)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def nms(outputs, max_boxes=MAX_BOXES, iou_threshold=IOU_THRES, score_threshold=SCORE_THRES):\n",
    "    \"\"\"\n",
    "    Computes Non-Max Supression\n",
    "    \"\"\"\n",
    "    boxes, conf, probs = [], [], []\n",
    "    \n",
    "    # extract values from the outputs\n",
    "    # outputs: [3,batch_size,grid_size,grid_size,anchors,(Normalized:[x1,y1,x2,y2]+ojectness+num_classes)]\n",
    "    for o in outputs:\n",
    "        boxes.append(tf.reshape(o[...,0:4], (tf.shape(o[...,0:4])[0], -1, tf.shape(o[...,0:4])[-1])))\n",
    "        conf.append(tf.reshape(o[...,4:5], (tf.shape(o[...,4:5])[0], -1, tf.shape(o[...,4:5])[-1])))\n",
    "        probs.append(tf.reshape(o[...,5:], (tf.shape(o[...,5:])[0], -1, tf.shape(o[...,5:])[-1])))\n",
    "    \n",
    "    bbox = tf.concat(boxes, axis=1) # [..., 4] \n",
    "    confidence = tf.concat(conf, axis=1) # [..., 1]\n",
    "    class_probs = tf.concat(probs, axis=1) # [..., num_classes]\n",
    "    #print(bbox.shape, confidence.shape, class_probs.shape)\n",
    "    \n",
    "    # calculate the scores\n",
    "    scores = confidence * class_probs\n",
    "    \n",
    "    # Compute Non-Max Supression\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        # [batch_size, num_boxes, num_classes, 4]\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        # [batch_size, num_boxes, num_classes]\n",
    "        scores=tf.reshape(scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])), \n",
    "        max_output_size_per_class=max_boxes,\n",
    "        max_total_size=max_boxes,\n",
    "        iou_threshold=iou_threshold,\n",
    "        score_threshold=score_threshold)\n",
    "    \n",
    "    # shapes: [batch_size, max_boxes, 4], [batch_size, max_boxes], ..., [batch_size]\n",
    "    return boxes , scores, classes, valid_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Load weights` Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "YOLOV3_LAYER_LIST = [\n",
    "   'DARKNET-53',\n",
    "   'YOLO_LAYER_0',\n",
    "   'YOLO_OUTPUT_0',\n",
    "   'YOLO_LAYER_1',\n",
    "   'YOLO_OUTPUT_1',\n",
    "   'YOLO_LAYER_2',\n",
    "   'YOLO_OUTPUT_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import logging\n",
    "\n",
    "def load_weights(model, weights_file, layers):\n",
    "    wf = open(weights_file, 'rb')\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    for layer_name in layers:\n",
    "        sub_model = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(sub_model.layers):\n",
    "            if not layer.name.startswith('conv2d'):\n",
    "                continue\n",
    "            batch_norm = None\n",
    "            if i + 1 < len(sub_model.layers) and \\\n",
    "                    sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
    "                batch_norm = sub_model.layers[i + 1]\n",
    "\n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            in_dim = layer.get_input_shape_at(0)[-1]\n",
    "\n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                # darknet [beta, gamma, mean, variance]\n",
    "                bn_weights = np.fromfile(\n",
    "                    wf, dtype=np.float32, count=4 * filters)\n",
    "                # tf [gamma, beta, mean, variance]\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "\n",
    "            # darknet shape (out_dim, in_dim, height, width)\n",
    "            conv_shape = (filters, in_dim, size, size)\n",
    "            conv_weights = np.fromfile(\n",
    "                wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            # tf shape (height, width, in_dim, out_dim)\n",
    "            conv_weights = conv_weights.reshape(\n",
    "                conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "                \n",
    "        percent_comp = (counter / len(layers)) * 100\n",
    "        \n",
    "        print('[INFO] Loading weights. Please Wait...{:.2f}% Complete'.format(percent_comp),\n",
    "              end = '\\r', flush = True)\n",
    "        counter += 1\n",
    "    \n",
    "    assert len(wf.read()) == 0, 'failed to read all data'\n",
    "    wf.close()\n",
    "    print(\"\\n[INFO] Weights Loaded Successfully ... \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `YOLO` CLass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class YOLO_V3(keras.Model):\n",
    "    \"\"\"\n",
    "    Creates a keras.Model instnace for YOLO_V3\n",
    "    \n",
    "    Arguments:\n",
    "        1. size = Integer (size of the input image)\n",
    "                  [default=416]\n",
    "        2. channels = Integer (no of input channels)\n",
    "                      [default = 3]\n",
    "        3. num_classes = Integer (no. of output_classes)\n",
    "                         [default=3]\n",
    "        4. anchors = Array (YOLO anchors) [default = cfg file anchors]\n",
    "        5. mask = Array (YOLO Mask) [default = cfg file mask]\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 size=INPUT_SIZE,\n",
    "                 channels=CHANNELS,\n",
    "                 num_classes=NUM_CLASSES,\n",
    "                 anchors=ANCHORS,\n",
    "                 mask = MASK):\n",
    "        \n",
    "        super(YOLO_V3, self).__init__()\n",
    "        self.yolo_V3 = YOLO(size, channels, anchors, mask, num_classes)\n",
    "        self.anchors = anchors\n",
    "        self.mask = mask\n",
    "        self.classes = num_classes\n",
    "        self.layer_list = YOLOV3_LAYER_LIST\n",
    "        \n",
    "    def call(self, inputs,training=False):\n",
    "        return self.yolo_V3(inputs,training=training)\n",
    "    \n",
    "    def load_darknet_weights(self, pth=WEIGHT_FILE):\n",
    "        \"\"\"\n",
    "        Loads the Darknet Model Weights\n",
    "        Arguments:\n",
    "        ---------\n",
    "            1. Path to the darknet weight file\n",
    "        \"\"\"\n",
    "        load_weights(self.yolo_V3, pth, self.layer_list)\n",
    "        \n",
    "    def predict(self, x, \n",
    "                max_boxes=MAX_BOXES,\n",
    "                iou_threshold=IOU_THRES,\n",
    "                score_threshold=SCORE_THRES,\n",
    "                verbose=0):\n",
    "        \"\"\"\n",
    "        Predicts bounding_boxes, scores & number of objects detected\n",
    "        \n",
    "        Arguments:\n",
    "           1. x = Tensor or Array([batch_size,size,size,channels])[input image]\n",
    "           2. max_boxes = Integer [Maximum number of boxes to detect in 1 image]\n",
    "                          (default=100)\n",
    "           3. iou_threshold = Float [IOU threshold for detecting boxes]\n",
    "                              (default=0.5)\n",
    "           4. score_threshold = Float [SCORE threshold for filtering boxes]\n",
    "                                (default=0.5)\n",
    "           5. verbose = Verbosity (default=0)\n",
    "        \"\"\"\n",
    "        super(YOLO_V3, self).predict(x=x, verbose=verbose)\n",
    "        outputs = self(x, training=False)\n",
    "        output_0, output_1, output_2 = outputs\n",
    "        \n",
    "        preds_0 = keras.layers.Lambda(\n",
    "            lambda x: decode_preds(x,self.anchors[self.mask[0]], self.classes))((output_0))\n",
    "        \n",
    "        preds_1 = keras.layers.Lambda(\n",
    "            lambda x: decode_preds(x,self.anchors[self.mask[1]], self.classes))((output_1))\n",
    "        \n",
    "        preds_2 = keras.layers.Lambda(\n",
    "            lambda x: decode_preds(x,self.anchors[self.mask[2]], self.classes))((output_2))\n",
    "        \n",
    "        outputs = keras.layers.Lambda(\n",
    "            lambda x: nms(x, max_boxes, iou_threshold, score_threshold)\n",
    "        )((preds_0[:3], preds_1[:3], preds_2[:3]))\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def compile(optimizer, run_eagerly=False):\n",
    "        super(YOLO_V3, self).compile(run_eagerly=run_eagerly)\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def train_step():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Testing` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from bounding_box import bounding_box as bb\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO_V3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_darknet_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model.yolo_V3, to_file=str(OUTPUT_DIR/\"model.png\"), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO Class names\n",
    "CLASS_FILE = \"../Vision/yolo/coco.names\"\n",
    "class_names = [c.strip() for c in open(CLASS_FILE).readlines()]\n",
    "class_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "COLOR_LIST = ['navy', 'blue', 'aqua',\n",
    "              'teal', 'olive', 'green', \n",
    "              'lime', 'yellow', 'orange',\n",
    "              'red', 'maroon', 'fuchsia',\n",
    "              'purple', 'black', 'gray' ,\n",
    "              'silver']\n",
    "\n",
    "id_list = list(np.arange(0, 81))\n",
    "\n",
    "COLOR_MAPPING = {}\n",
    "for idx in id_list:  COLOR_MAPPING[idx] = random.choice(COLOR_LIST)\n",
    "\n",
    "print(COLOR_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def detect(IMG_FILE:str, model, file=None, display=True, verbose=1, **kwargs):\n",
    "    \"\"\"\n",
    "    Draws outputs on the image\n",
    "    \n",
    "    Arguments:\n",
    "     1. image_file\n",
    "     2. model [Required]\n",
    "     3. file [Optional] [filepath where to save results]\n",
    "     4. display [Optional] [Wether to display the Image]\n",
    "     5. **kwargs [Arguments for model.predict() function] [Optional]\n",
    "    \"\"\"\n",
    "    try:     img = cv2.imread(IMG_FILE)\n",
    "    except:  img = IMG_FILE\n",
    "    \n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    im = tf.cast(img/255, tf.float32)\n",
    "    im = tf.image.resize(im,size=[INPUT_SIZE,INPUT_SIZE])\n",
    "    im = tf.expand_dims(im,axis=0)\n",
    "    \n",
    "    boxes, scores, classes, nums = model.predict(im, **kwargs)\n",
    "    \n",
    "    boxes, objectness, classes, nums = boxes[0], scores[0], classes[0], nums[0]\n",
    "    \n",
    "    if verbose >0 :print(\"[INFO] Number of objects detected: \", int(nums))\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    for i in range(nums):\n",
    "        # Grab the xmin,xmax,ymin,ymax values\n",
    "        x1y1 = tuple(np.array(boxes[i][0:2]*wh).astype(np.int32))\n",
    "        x2y2 = tuple(np.array(boxes[i][2:4]*wh).astype(np.int32))\n",
    "        \n",
    "        cls_id = int(classes[i])\n",
    "        \n",
    "        label = class_names[cls_id] + ': {:.1f}'.format(objectness[i])\n",
    "        \n",
    "        bb.add(img, x1y1[0], x1y1[1], x2y2[0], x2y2[1], label=label, color=COLOR_MAPPING[cls_id])\n",
    "        \n",
    "        percent_comp = (counter/nums) * 100\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print('[INFO] Drawing Predicitons. Please Wait...{:.2f}% Complete'\n",
    "                  .format(percent_comp),end = '\\r', flush = True)\n",
    "        \n",
    "        counter += 1\n",
    "\n",
    "    # display the image if output output file is not given\n",
    "    if  display:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(22,22))\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    elif not display and file is None:\n",
    "        return img\n",
    "    \n",
    "    # else save the image at file\n",
    "    if file is not None:\n",
    "        cv2.imwrite(file, cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        if verbose > 0: print(f\"\\n[INFO] Results saved at {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(\"data/val2017/000000000632.jpg\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(\"data/car.jpg\", model=model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(\"data/image_1.jpg\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(\"data/val2017/000000038829.jpg\", model, file=\"outputs/result.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"outputs/result.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video(video:str, model, output:str, **kwargs):\n",
    "    \"\"\"Draw Bounding box over VideoFile\"\"\"\n",
    "    # initialize the video stream, pointer to the output video file,\n",
    "    # and frame dimensions\n",
    "    vs = cv2.VideoCapture(video)\n",
    "    writer = None\n",
    "    (W,H) = (None,None)\n",
    "    \n",
    "    # try to determin total number of images in the frame\n",
    "    try:\n",
    "        prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() else cv2.CAP_PROP_FRAME_COUNT\n",
    "        total = int(vs.get(prop))\n",
    "        print(\"[INFO] {} total frames in video\".format(total))\n",
    "    # an error occurred while trying to determine the total\n",
    "    # number of frames in the video file\n",
    "    except:\n",
    "        print(\"[INFO] could not determine # of frames in video\")\n",
    "        print(\"[INFO] no approx. completion time can be provided\")\n",
    "        total = -1    \n",
    "    \n",
    "    print('[INFO] Drawing Predicitons', end=\"\\t\")\n",
    "    if total > 0: bar = tqdm(range(total), leave=False)\n",
    "    # loop over frames from the video file stream\n",
    "    while True:\n",
    "            \n",
    "        # read the next frame from the file\n",
    "        (grabbed, frame) = vs.read()\n",
    "        \n",
    "        # if the frame was not grabbed, then we have reached the end\n",
    "        # of the stream\n",
    "        if not grabbed:     break\n",
    "            \n",
    "        # if the frame dimensions are empty, grab them\n",
    "        if W is None or H is None:   (H, W) = frame.shape[:2]\n",
    "            \n",
    "        # Draw the bboxs on the image\n",
    "        frame = detect(frame, model, display=False, **kwargs, verbose=0)\n",
    "        \n",
    "        # check if the video writer is None\n",
    "        if writer is None:\n",
    "            # initialize video writer\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MP4V\")\n",
    "            writer = cv2.VideoWriter(output, fourcc, 30,(frame.shape[1], frame.shape[0]), True)\n",
    "        \n",
    "        # write the output frame to disk\n",
    "        writer.write(frame)\n",
    "        bar.update(1)\n",
    "        \n",
    "    # release the file pointers\n",
    "    print(\"[INFO] cleaning up...\")\n",
    "    print(f\"[INFO] output saved to {output} ... \")\n",
    "    writer.release()\n",
    "    vs.release()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_video(video=\"outputs/crowd copy.mp4\", model=model, output=\"outputs/crowd_yolo_res.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
